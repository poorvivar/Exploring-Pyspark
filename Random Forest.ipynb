{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline, classification\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark import sql\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_rf_clean = pd.read_csv('flights_indexed_clean.csv')\n",
    "flights_rf_clean = flights_rf_clean.drop(columns=['CANCELLED', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_rf_clean = spark.createDataFrame(flights_rf_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_training_df, rf_validation_df, rf_testing_df = flights_rf_clean.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Pipeline #\n",
    "\n",
    "## EXPERIMENT:  See the pipeline section above ##\n",
    "\n",
    "pipe_randomforest = Pipeline(stages = [\n",
    "    feature.VectorAssembler(inputCols=['DIVERTED',\n",
    " 'AIRLINE_index',\n",
    " 'FLIGHT_NUMBER_index',\n",
    " 'TAIL_NUMBER_index',\n",
    " 'ORIGIN_AIRPORT_index',\n",
    " 'DESTINATION_AIRPORT_index',\n",
    " 'SCHEDULED_DEPARTURE_index',\n",
    " 'SCHEDULED_TIME_index',\n",
    " 'SCHEDULED_ARRIVAL_index'], outputCol='features',),\n",
    "    classification.RandomForestClassifier(numTrees=20, maxDepth=13, featuresCol='features',labelCol='DEPARTURE_DELAY_index',)\\\n",
    "    .setSeed(0)\n",
    "]).fit(rf_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_df = pipe_randomforest.transform(rf_validation_df).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>14030</td>\n",
       "      <td>6950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2257</td>\n",
       "      <td>3066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label         0.0   1.0\n",
       "prediction             \n",
       "0.0         14030  6950\n",
       "1.0          2257  3066"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.996%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 36452)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe which contains the random forest predictions, as well as the actual label,\n",
    "# and then build a confusion matrix #\n",
    "\n",
    "evaluation_df = pd.concat([randomforest_df['prediction'],randomforest_df['DEPARTURE_DELAY_index']], \n",
    "                          axis = 1, keys=['prediction','label'])\n",
    "crosstab_df = pd.crosstab(evaluation_df.prediction, evaluation_df.label)\n",
    "display(crosstab_df)\n",
    "print(\"Accuracy: {:,.3f}%\" .format((crosstab_df[0][0] + crosstab_df[1][1]) / crosstab_df.values.sum() * 100))\n",
    "\n",
    "# Less accurate than our previous model, but that would make sense because it has less information available #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
